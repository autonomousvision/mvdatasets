{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rays generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rays(camera):\n",
    "        \"\"\"\n",
    "        Generate rays in world space for each pixel.\n",
    "\n",
    "        Returns:\n",
    "        rays_o (torch.tensor): centers of each ray. (H*W, 3)\n",
    "        rays_d (torch.tensor): direction of each ray (a unit vector). (H*W, 3)\n",
    "        \"\"\"\n",
    "\n",
    "        # pose = camera.get_pose()\n",
    "\n",
    "        # generate pixel coords (H, W), (H, W)\n",
    "        tx = torch.arange(0, camera.height, 1)\n",
    "        ty = torch.arange(0, camera.width, 1)\n",
    "        pixels_x, pixels_y = torch.meshgrid(tx, ty, indexing=\"ij\")\n",
    "        color = camera.img[(pixels_y, pixels_x)] \n",
    "\n",
    "        # (u, v, 1) (W * H, 3)\n",
    "        pixels = torch.stack([pixels_x, pixels_y, torch.ones_like(pixels_y)], dim=-1).view(-1, 3).float()\n",
    "\n",
    "        # points = (camera.intrinsics_inv @ pixels.T).T\n",
    "        # print(points.shape)\n",
    "\n",
    "        # p = torch.matmul(intrinsics, p[:, :, :, None]).squeeze()\n",
    "        # W, H, 3\n",
    "        # p = torch.matmul(intrinsics, p[:, :, :, None]).squeeze()\n",
    "        # print(p.shape)\n",
    "        # # W, H, 3\n",
    "        # rays_d = p / torch.linalg.norm(p, ord=2, dim=-1, keepdim=True)\n",
    "        # print(rays_d.shape)\n",
    "        # # W, H, 3\n",
    "        # rays_d = torch.matmul(pose[None, :3, :3], rays_d[:, :, :, None]).squeeze()\n",
    "        # # W, H, 3\n",
    "\n",
    "        # replicate origin for each pixel\n",
    "        # rays_o = pose[None, :3, 3].expand(camera.nr_pixels, -1)\n",
    "\n",
    "        return None, None, color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera = training_data.cameras[0]\n",
    "# tx = torch.arange(0, camera.height, 1)\n",
    "# ty = torch.arange(0, camera.width, 1)\n",
    "# pixels_x, pixels_y = torch.meshgrid(tx, ty, indexing=\"ij\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rays_o, rays_d, color = get_rays(training_data.cameras[0])\n",
    "\n",
    "# # print(rays_o.shape)\n",
    "# # print(rays_d.shape)\n",
    "# print(color.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # random in range without repetitions \n",
    "# ii = torch.randperm(training_data.cameras[0].width)[:10].repeat(10, 1)\n",
    "# jj = torch.randperm(training_data.cameras[0].height)[:10].view(-1, 1).repeat(1, 10)\n",
    "# print(ii.shape)\n",
    "# print(jj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # (H, W), (H, W)\n",
    "# # ii, jj = torch.meshgrid(\n",
    "# #     torch.arange(0, training_data.cameras[0].width, 1),\n",
    "# #     torch.arange(0, training_data.cameras[0].height, 1),\n",
    "# #     indexing=\"xy\",\n",
    "# # )\n",
    "# # print(ii.shape)\n",
    "# # print(jj.shape)\n",
    "\n",
    "# # (H, W, 3)\n",
    "# local_rays_d = torch.stack(\n",
    "#     [\n",
    "#         (ii - training_data.cameras[0].width * 0.5) / training_data.cameras[0].intrinsics[0, 0],\n",
    "#         -(jj - training_data.cameras[0].height * 0.5) / training_data.cameras[0].intrinsics[1, 1],\n",
    "#         -torch.ones_like(ii),\n",
    "#     ],\n",
    "#     dim=-1,\n",
    "# )\n",
    "# print(local_rays_d.shape)\n",
    "\n",
    "# rays_d = torch.sum(local_rays_d[..., None, :] * training_data.cameras[0].get_pose()[:3, :3], dim=-1)\n",
    "# rays_d = rays_d / torch.norm(rays_d, dim=-1, keepdim=True)\n",
    "# rays_d = rays_d.view(-1, 3)\n",
    "# print(rays_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nr_rays = 120\n",
    "# subsample = 4\n",
    "# nr_steps = nr_rays // subsample\n",
    "# print(nr_steps)\n",
    "# steps = nr_rays // (nr_rays // subsample)\n",
    "# print(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from datasets.visualization.matplotlib import plot_camera_rays\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from itertools import product, combinations\n",
    "# def plot_camera_rays(camera, azimuth_deg=60, elevation_deg=30, subsample=1.0):\n",
    "#     \"\"\"\n",
    "#     Plot camera rays in 3D.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Get all camera poses\n",
    "#     pose = camera.get_pose().cpu().numpy()\n",
    "\n",
    "#     rays_o, rays_d = camera.get_rays()  # TODO: get random rays\n",
    "#     nr_rays = rays_o.shape[0]\n",
    "#     print(rays_d.shape)\n",
    "#     rays_idx = np.arange(0, nr_rays, nr_rays // (nr_rays // subsample), dtype=np.int32)\n",
    "#     rays_d = rays_d.cpu().numpy()[rays_idx]\n",
    "#     print(rays_d.shape)\n",
    "#     print(rays_idx.shape)\n",
    "    \n",
    "#     # Get all camera centers\n",
    "#     camera_center = pose[:3, 3]\n",
    "\n",
    "#     scale = np.max(np.linalg.norm(camera_center)) * 0.1\n",
    "\n",
    "#     fig = plt.figure(figsize=(10, 10))\n",
    "#     ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "#     # Cartesian axes\n",
    "#     ax.quiver(0, 0, 0, 1, 0, 0, length=scale, color=\"r\")\n",
    "#     ax.quiver(0, 0, 0, 0, 1, 0, length=scale, color=\"g\")\n",
    "#     ax.quiver(0, 0, 0, 0, 0, 1, length=scale, color=\"b\")\n",
    "#     ax.text(0, 0, 0, \"w\")\n",
    "\n",
    "#     # Draw bounding cube\n",
    "#     r = [-1, 1]\n",
    "#     for s, e in combinations(np.array(list(product(r, r, r))), 2):\n",
    "#         if np.sum(np.abs(s - e)) == r[1] - r[0]:\n",
    "#             ax.plot3D(*zip(s, e), color=\"black\")\n",
    "\n",
    "#     # Draw camera frame\n",
    "#     ax.quiver(\n",
    "#         pose[0, 3],\n",
    "#         pose[1, 3],\n",
    "#         pose[2, 3],\n",
    "#         pose[0, 0],\n",
    "#         pose[1, 0],\n",
    "#         pose[2, 0],\n",
    "#         length=scale,\n",
    "#         color=\"r\",\n",
    "#     )\n",
    "#     ax.quiver(\n",
    "#         pose[0, 3],\n",
    "#         pose[1, 3],\n",
    "#         pose[2, 3],\n",
    "#         pose[0, 1],\n",
    "#         pose[1, 1],\n",
    "#         pose[2, 1],\n",
    "#         length=scale,\n",
    "#         color=\"g\",\n",
    "#     )\n",
    "#     ax.quiver(\n",
    "#         pose[0, 3],\n",
    "#         pose[1, 3],\n",
    "#         pose[2, 3],\n",
    "#         pose[0, 2],\n",
    "#         pose[1, 2],\n",
    "#         pose[2, 2],\n",
    "#         length=scale,\n",
    "#         color=\"b\",\n",
    "#     )\n",
    "#     ax.text(pose[0, 3], pose[1, 3], pose[2, 3], \"c\")\n",
    "\n",
    "#     # Draw rays\n",
    "#     for ray in rays_d:\n",
    "#         ax.quiver(\n",
    "#             camera_center[0],\n",
    "#             camera_center[1],\n",
    "#             camera_center[2],\n",
    "#             ray[0],\n",
    "#             ray[1],\n",
    "#             ray[2],\n",
    "#             length=5,\n",
    "#             color=\"g\",\n",
    "#         )\n",
    "    \n",
    "#     min_lim = np.min(camera_center)\n",
    "#     max_lim = np.max(camera_center)\n",
    "#     lim = np.max([abs(min_lim), abs(max_lim)]) + scale\n",
    "#     ax.set_xlim([-lim, lim])\n",
    "#     ax.set_ylim([-lim, lim])\n",
    "#     ax.set_zlim([-lim, lim])\n",
    "\n",
    "#     ax.set_xlabel(\"X\")\n",
    "#     ax.set_ylabel(\"Y\")\n",
    "#     ax.set_zlabel(\"Z\")\n",
    "\n",
    "#     # axis equal\n",
    "#     ax.set_aspect(\"equal\")\n",
    "#     ax.view_init(elevation_deg, azimuth_deg)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_camera_rays(training_data.cameras[0], azimuth_deg=60, elevation_deg=30, subsample=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dataloader\n",
    "# train_dataloader = torch.utils.data.DataLoader(training_data, batch_size=1, shuffle=False, num_workers=0)\n",
    "# # test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "# data = next(iter(train_dataloader))\n",
    "# intrinsics = data[0]\n",
    "# pose = data[1]\n",
    "# img = data[2]\n",
    "# mask = data[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
